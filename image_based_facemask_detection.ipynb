{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3833 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set_gen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "train_data=train_set_gen.flow_from_directory(\"dataset/\",target_size=(224,224),batch_size=32,class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3833 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data=train_set_gen.flow_from_directory(\"dataset/\",target_size=(224,224),batch_size=32,class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,AveragePooling2D,Dense,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=3,activation=\"relu\",input_shape=[224,224,3]))\n",
    "model.add(AveragePooling2D(pool_size=(7, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=3,activation=\"relu\"))\n",
    "model.add(AveragePooling2D(pool_size=(7, 7)))\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=50,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                25650     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 35,845\n",
      "Trainable params: 35,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 97/120 [=======================>......] - ETA: 36s - loss: 0.4398 - accuracy: 0.8111"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:973: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 250s 2s/step - loss: 0.4055 - accuracy: 0.8294 - val_loss: 0.2440 - val_accuracy: 0.9100\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 201s 2s/step - loss: 0.2780 - accuracy: 0.9022 - val_loss: 0.2225 - val_accuracy: 0.9223\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 185s 2s/step - loss: 0.2295 - accuracy: 0.9170 - val_loss: 0.1942 - val_accuracy: 0.9277\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 190s 2s/step - loss: 0.2183 - accuracy: 0.9209 - val_loss: 0.1854 - val_accuracy: 0.9309\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 200s 2s/step - loss: 0.2152 - accuracy: 0.9225 - val_loss: 0.1808 - val_accuracy: 0.9309\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 199s 2s/step - loss: 0.2078 - accuracy: 0.9267 - val_loss: 0.2161 - val_accuracy: 0.9113\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 189s 2s/step - loss: 0.1904 - accuracy: 0.9285 - val_loss: 0.1648 - val_accuracy: 0.9390\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 188s 2s/step - loss: 0.1814 - accuracy: 0.9337 - val_loss: 0.1542 - val_accuracy: 0.9426\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 187s 2s/step - loss: 0.1733 - accuracy: 0.9348 - val_loss: 0.1588 - val_accuracy: 0.9418\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 189s 2s/step - loss: 0.1781 - accuracy: 0.9366 - val_loss: 0.1941 - val_accuracy: 0.9400\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 189s 2s/step - loss: 0.1716 - accuracy: 0.9363 - val_loss: 0.1407 - val_accuracy: 0.9499\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 188s 2s/step - loss: 0.1637 - accuracy: 0.9390 - val_loss: 0.1345 - val_accuracy: 0.9491\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 189s 2s/step - loss: 0.1626 - accuracy: 0.9434 - val_loss: 0.1361 - val_accuracy: 0.9486\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 188s 2s/step - loss: 0.1558 - accuracy: 0.9418 - val_loss: 0.1312 - val_accuracy: 0.9543\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 188s 2s/step - loss: 0.1554 - accuracy: 0.9439 - val_loss: 0.1466 - val_accuracy: 0.9447\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 189s 2s/step - loss: 0.1640 - accuracy: 0.9403 - val_loss: 0.1313 - val_accuracy: 0.9523\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 188s 2s/step - loss: 0.1507 - accuracy: 0.9483 - val_loss: 0.1228 - val_accuracy: 0.9546\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 187s 2s/step - loss: 0.1481 - accuracy: 0.9460 - val_loss: 0.1286 - val_accuracy: 0.9489\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 188s 2s/step - loss: 0.1371 - accuracy: 0.9504 - val_loss: 0.1198 - val_accuracy: 0.9538\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 187s 2s/step - loss: 0.1463 - accuracy: 0.9455 - val_loss: 0.1193 - val_accuracy: 0.9517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2048469e070>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,validation_data=test_data,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image With Mask\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "# my_model=load_model(\"my_mask_detector.model\")\n",
    "test_image=image.load_img('dataset/with_mask/with_mask511.jpg',target_size=(224,224))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=model.predict(test_image)\n",
    "\n",
    "if result[0][0]==0:\n",
    "    print(\"Image With Mask\")\n",
    "\n",
    "else:\n",
    "    print(\"Image Without Mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with_mask': 0, 'without_mask': 1}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
